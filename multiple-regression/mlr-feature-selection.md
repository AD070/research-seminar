Множественная регрессия: отбор факторов и диагностика модели
================
Заходякин Г.В., <postlogist@gmail.com>
21.02.2017

-   Введение
-   Подготовка
    -   [Загрузка пакетов](#-)
    -   [Загрузка данных](#-)
-   [Проблема мультиколлинеарности](#-)
    -   [Причина мультиколлинеарности](#-)
    -   [Как проявляется мультиколлинеарность](#--)
    -   [Как измерить степень проявления мультиколлинеарности](#----)
    -   [Линейная зависимость предикторов](#--)
    -   [Линейная зависимость между фиктивными переменными](#----)
-   [Отбор предикторов в модель](#---)
    -   [Полная модель](#-)
    -   [Критерии для выбора лучшей модели](#----)
    -   [Метод полного перебора](#--)
    -   [Пошаговая регрессия](#-)

Введение
========

В модель множественной регрессии можно включать несколько объясняющих переменных. Вопрос в том, какие именно переменные лучше всего включить. В этом блокноте мы рассмотрим на примере прогнозирования топливной эффективности машин несколько подходов к отбору факторов в модель. Также здесь рассмотрены вопросы определения наиболее важных предикторов среди включенных в модель и преобразования данных для облегчения интерпретации коэффициентов модели. В заключение будет затронута проблема диагностики модели.

Подготовка
==========

Загрузка пакетов
----------------

``` r
library(readr) # считывание данных из текстовых файлов
library(memisc) # удобное сравнение моделей в таблице
library(tidyverse) # манипулирование данными 
library(ggplot2) # визуализация 
library(ggfortify) # визуализация диагностических графиков
library(modelr) # вспомогательные функции для работы с моделями
library(broom) # преобразование результатов моделирования в табличный вид
library(GGally) # построение матрицы диаграмм рассеяния 
library(car) # функции для степенных преобразований
library(forcats) # работа с факторами
```

Загрузка данных
---------------

``` r
cars <- read_csv2("datasets/cars.csv", skip = 25) 
```

Разведочный анализ выполнялся в [первой части примера](mlr-modeling.Rmd). Здесь мы лишь исключим 5 наблюдений с пропущенными данными.

``` r
cars <- na.omit(cars)
```

Проблема мультиколлинеарности
=============================

Причина мультиколлинеарности
----------------------------

Рассмотрим матрицу диаграмм рассеяния для различных характеристик машин.

``` r
# Матрица диаграмм рассеяния
cars %>% 
  select_if(is.numeric) %>%
  ggpairs(lower = list(continuous = wrap("smooth_lm", color = 'blue')))
```

![](mlr-feature-selection_files/figure-markdown_github/Матрица%20диаграмм%20рассеяния-1.png)

Все количественные переменные коррелированы с `mpg`. Но можно видеть, что многие из них коррелированы и между собой. Например, коэффициент корреляции для длины машины и ее колесной базы равен 0.84. Эти переменные передают сходную информацию о машине:

![Колесная база](figures/wheelbase.png)

Термин **"мультиколлинеарность"** (*multicollinearity*) обозначает ситуацию, в которой несколько объясняющих переменных, включенных в модель, коррелированы между собой, т.е. несут дублирующуюся информацию. Мультиколлинеарность - это сильная линейная связь между двумя и более переменными в модели.

Как проявляется мультиколлинеарность
------------------------------------

Рассмотрим на примере, как мультиколлинеарность влияет на результаты моделирования. Для этого добавим к построенной ранее модели с весом и мищностью машины еще одну переменную - `fuel_cap` (емкость топливного бака). Сама по себе эта переменная - хороший предиктор для `mpg` и имеет второй по абсолютной величине коэффициент корреляции с `mpg`: *r* = −0.80. Однако эта переменная сильно коррелирована также и с весом машины: *r* = 0.86.

Изменения в модели удобно отразить в таблице, полученной с помощью функции `memisc::mtable()`.

``` r
m_wgtpow <- lm(mpg ~ curb_wgt + horsepow, data = cars)
m_wgtpowfuel <- lm(mpg ~ curb_wgt + horsepow + fuel_cap, data = cars)

memisc::mtable(m_wgtpow, m_wgtpowfuel)
```

    ## 
    ## Calls:
    ## m_wgtpow: lm(formula = mpg ~ curb_wgt + horsepow, data = cars)
    ## m_wgtpowfuel: lm(formula = mpg ~ curb_wgt + horsepow + fuel_cap, data = cars)
    ## 
    ## ===========================================
    ##                   m_wgtpow   m_wgtpowfuel  
    ## -------------------------------------------
    ##   (Intercept)     42.567***   42.525***    
    ##                   (1.054)     (0.991)      
    ##   curb_wgt        -4.782***   -2.463***    
    ##                   (0.387)     (0.627)      
    ##   horsepow        -0.014**    -0.015***    
    ##                   (0.004)     (0.004)      
    ##   fuel_cap                    -0.423***    
    ##                               (0.093)      
    ## -------------------------------------------
    ##   R-squared           0.7         0.7      
    ##   adj. R-squared      0.7         0.7      
    ##   sigma               2.4         2.3      
    ##   F                 168.4       133.9      
    ##   p                   0.0         0.0      
    ##   Log-likelihood   -347.2      -337.3      
    ##   Deviance          858.3       753.3      
    ##   AIC               702.5       684.6      
    ##   BIC               714.6       699.8      
    ##   N                 152         152        
    ## ===========================================

После добавления еще одной переменной качество модели практически не изменилось: на 0.1 снизилась стандартная ошибка, а коэффициент детерминации остался прежним (с точностью до одного десятичного знака).

Но обратим внимание на то, что стандартная ошибка для коэффициента `curb_wgt` увеличилась почти вдвое. Это означает, что погрешность оценки этого коэффициента увеличилась. Это - одно из негативных проявлений мультиколлинеарности.

Помимо увеличения стандартных ошибок для угловых коэффициентов, мультиколлинеарность затрудняет интерпретацию отдельных коэффициентов. Ранее мы предполагали, что вклад каждого предиктора независим от других и интерпретировали угловой коэффициент *b*<sub>*j*</sub> как предельный эффект для предиктора *x*<sub>*j*</sub>, т.е. как изменение *y* при единичном изменении *x*<sub>*j*</sub> и зафиксированных значениях остальных предикторов. Но поскольку теперь в модели есть взаимосвязанные предикторы, например вес машины и размер топливного бака, больше невозможно изменять эти величины поотдельности. Для более тяжелой машины нужен больший топливный бак, потому что ей нужно больше топлива.

В теории множественной регрессии доказывается, что оценки коэффициентов модели взаимосвязаны между собой. Связь между ними характеризуется **ковариационной матрицей** модели (*variance-covariance matrix*), которая получается как один из побочных результатов применения метода наименьших квадратов. Эта матрица содержит на главной диагонали дисперсии оценок коэффициентов (т.е. квадраты их стандартных ошибок), а для недиагональных элементов - ковариации оценок соответствующих коэффициентов модели.

``` r
round(vcov(m_wgtpowfuel), 3)
```

    ##             (Intercept) curb_wgt horsepow fuel_cap
    ## (Intercept)       0.982   -0.285    0.000    0.001
    ## curb_wgt         -0.285    0.393   -0.001   -0.047
    ## horsepow          0.000   -0.001    0.000    0.000
    ## fuel_cap          0.001   -0.047    0.000    0.009

Если два коэффициента имеют большую ковариацию, то стандартная ошибка для коэффициентов увеличится. Также, если один из предикторов исключить из модели, то изменится значение коэффициента для оставшегося предиктора. В некоторых случаях может поменяться даже направленность связи (знак коэффициента). Например, может оказаться, что в модели предсказания спроса цена будет иметь положительный угловой коэффициент, что невозможно с точки зрения здравого смысла.

Как измерить степень проявления мультиколлинеарности
----------------------------------------------------

Для измерения степени выраженности мультиколлинеарности, используется показатель **коэффициента роста дисперсии** (*variance inflation factor*), который вычисляется для каждого предиктора в модели:

$$ VIF\_j = \\frac{1}{1-R^2\_j}, j=1 \\ldots k $$

В этой формуле *R*<sub>*j*</sub><sup>2</sup> - коэффициент детерминации регрессии предиктора *j* на остальные *k* − 1 предикторов. Этот коэффициент показывает, насколько остальные предикторы повторяют информацию, содержащуюся в предикторе *j*. Для модели с *k* = 2 предикторами, *R*<sub>*j*</sub><sup>2</sup> - это квадрат коэффициента корреляции между этими предикторами.

Если предиктор *j* не дублирует информацию из других переменных, т.е. не связан с ними линейными зависимостями, то *R*<sub>*j*</sub><sup>2</sup> = 0 и *V**I**F*<sub>*j*</sub> = 1. Если такие зависимости есть, то *V**I**F*<sub>*j*</sub> &gt; 1.

Близкое к 1 значение *V**I**F*<sub>*j*</sub> позволяет заключить, что мультиколлинеарность при добавлении предиктора *j* в модель отсуствует или незначительна. Этот предиктор не меняет стандартные ошибки и значения других коэффициентов в модели.

Если значение *V**I**F*<sub>*j*</sub> ≫ 1, то оценка углового для этого коэффициента нестабильна. При изменении набора предикторов коэффициент может сильно измениться, или стать незначимым. Большое значение *V**I**F* означает дублирование информации в различных предикторах. Информация, добавленная с переменной, у которой большой *V**I**F*, уже была объяснена другими переменными в модели.

При *V**I**F* &gt; 4 можно предположить выраженную мультиколлинеарность.

Для вычисления коэффициентов роста дисперсии в R используется функция `vif()`:

``` r
vif(m_wgtpowfuel) %>% 
  round(1)
```

    ## curb_wgt horsepow fuel_cap 
    ##      4.7      1.6      4.0

Хотя мультиколлинеарность и создает проблемы для статистического вывода (оценки значимости коэффициентов) и интерпретации угловых коэффициентов, она никак не мешает прогнозированию по данной модели. Проблема при прогнозировании возникает только если коэффициентов в модели очень много и для оценки каждого из них приходится всего несколько наблюдений (т.е. отношение числа наблюдений к числу коэффициентов мало). В этом случае модель может переобучиться - запомнить случайный шум, присутствующий в исходных данных вместо закономерных связей. Переобученная модель дает плохой результат при прогнозировании на новых данных.

Линейная зависимость предикторов
--------------------------------

В случае, когда мультиколлинеарность является строгой, т.е. несколько объясняющих переменных в модели связаны совершенной линейной зависимостью, коэффициенты модели невозможно оценить. В формуле для вычисления коэффициентов используется операция обращения матрицы данных, которая может быть выполнена только при условии линейной независимости столбцов.

Вычислим ширину машины в сантиметрах на основе ширины в дюймах и попытаемся оценить модель, в которую включены эти два предиктора. Очевидно, что один из них может быть вычислен на основе другого с помощью умножения на константу, т.е. они линейно зависимы.

``` r
cars_multi <- cars %>%
  mutate(width_cm = width * 2.54)

m_width_cm <- lm(mpg ~ width_cm, data = cars_multi)
coef(m_width_cm) # нет проблем
```

    ## (Intercept)    width_cm 
    ##      77.050      -0.295

``` r
m_width_both <- lm(mpg ~ width + width_cm, data = cars_multi)
coef(m_width_both) # одна из линейно зависимых переменных автоматически исключена
```

    ## (Intercept)       width    width_cm 
    ##      77.050      -0.748          NA

Линейная зависимость между фиктивными переменными
-------------------------------------------------

Частным случаем линейной зависимости между предикторами является линейная зависимость между фиктивными переменными (**dummy trap**). Линейная зависимость между фиктивными переменными возникает, если включить в модель фиктивную переменную для каждой группы. Например, ранее мы строили модель зависимости пробега от мощности с учетом типа машины. Чтобы учесть тип, который является дискретной переменной (грузовик или легковой автомобиль), необходимо преобразовать тип в фиктивные переменные. Мы создали переменную `truck`, котороая принимает значение 1 для грузовиков и 0 для автомобилей. Если же включить в модель еще одну переменную - `automobile`, которая принимает значение 1 уже для легковых машин, то переменные окажутся линейно зависимыми. Машина может быть либо грузовиком, либо легковым автомобилем, поэтому справедливо равенство:

*a**u**t**o**m**o**b**i**l**e* + *t**r**u**c**k* = 1

Из этого следует, что зная одну из переменных можно всегда определить значение второй, т.е. они линейно зависимы.

``` r
cars_dummy <- cars %>%
  mutate(truck = ifelse(type == 'Truck', 1, 0), 
         automobile = ifelse(type == 'Automobile', 1, 0))

m_dummy <- lm(mpg ~ horsepow + truck + automobile, data = cars_dummy)
coef(m_dummy) # Включена только одна фиктивная переменная
```

    ## (Intercept)    horsepow       truck  automobile 
    ##      33.788      -0.046      -5.521          NA

Количество фиктивных переменных, необходимых для учета в модели категориальной переменной, должно быть на единицу меньше числа категорий, чтобы предотвратить линейную зависимость. Вспомним, что базовой категорией будет та, для которой в модель не включена фиктивная переменная. Коэффициенты для включенных в модель фиктивных переменных показывают отличия соответствующих групп от базовой.

В R для моделирования дискретных переменных лучше использовать факторы, при этом фиктивные переменные создаются автоматически и линейной зависимости между ними не может возникнуть в принципе.

Отбор предикторов в модель
==========================

Полная модель
-------------

Попробуем построить **полную модель** (*full model*), включающую всю доступную информацию, т.е. все количественные переменные в наборе данных, а также тип машины и страну производителя.

``` r
m_full <- lm(mpg ~ ., data = dplyr::select(cars, country:mpg)) # Символ . обозначает все переменные в таблице

summary(m_full)
```

    ## 
    ## Call:
    ## lm(formula = mpg ~ ., data = dplyr::select(cars, country:mpg))
    ## 
    ## Residuals:
    ##    Min     1Q Median     3Q    Max 
    ## -6.654 -1.029  0.003  1.008 11.636 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  39.11049    5.04830    7.75  1.7e-12 ***
    ## countryJapan  1.39782    0.60128    2.32   0.0215 *  
    ## countryUSA    2.02917    0.68949    2.94   0.0038 ** 
    ## typeTruck    -3.20122    0.68318   -4.69  6.5e-06 ***
    ## price         0.04769    0.02832    1.68   0.0945 .  
    ## engine_s     -1.10242    0.44745   -2.46   0.0150 *  
    ## horsepow     -0.01911    0.00868   -2.20   0.0293 *  
    ## wheelbas      0.06803    0.04873    1.40   0.1648    
    ## width        -0.06902    0.08822   -0.78   0.4353    
    ## length       -0.02091    0.03060   -0.68   0.4955    
    ## curb_wgt     -1.41505    0.71937   -1.97   0.0512 .  
    ## fuel_cap     -0.22041    0.09586   -2.30   0.0230 *  
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 2.02 on 140 degrees of freedom
    ## Multiple R-squared:  0.796,  Adjusted R-squared:  0.779 
    ## F-statistic: 49.5 on 11 and 140 DF,  p-value: <2e-16

``` r
vif(m_full) %>% round(1)
```

    ##          GVIF Df GVIF^(1/(2*Df))
    ## country   3.3  2             1.3
    ## type      3.4  1             1.8
    ## price     6.2  1             2.5
    ## engine_s  8.2  1             2.9
    ## horsepow  9.0  1             3.0
    ## wheelbas  5.2  1             2.3
    ## width     3.5  1             1.9
    ## length    6.3  1             2.5
    ## curb_wgt  7.7  1             2.8
    ## fuel_cap  5.3  1             2.3

У предикторов большие коэффициенты роста дисперсии (VIF). Некоторые угловые коэффициенты незначимы из-за больших стандартных ошибок. Причина в том, что многие объясняющие переменные взаимосвязаны и несут дублирующуюся информацию. Необходимо упростить модель.

Критерии для выбора лучшей модели
---------------------------------

До сих пор, мы ориентировались на коэффициент детерминации *R*<sup>2</sup> для сравнения моделей. Однако у этого показателя есть ограничения. Можно показать, что при усложнении модели путем включения дополнительных переменных величина *R*<sup>2</sup> всегда увеличивается, даже если новые переменные не несут дополнительной информации. Таким образом, с помощью *R*<sup>2</sup> можно сравнивать только модели, у которых одинаковое число предикторов.

На практике для выбора моделей используются другие показатели, которые на имеют этой проблемы:

-   Скорректированный *R*<sup>2</sup> (Adjusted *R*<sup>2</sup>)
-   Информационный критерий Акаике (Akaike Information Criterion, AIC)
-   Модифицированный информационный критерий Акаике, (Corrected AIC, AICc)
-   Байесовский информационный критерий Шварца (Bayesian Information Criterion, BIC)
-   Статистика [Mallow's Cp](https://en.wikipedia.org/wiki/Mallows's_Cp)

Все эти показатели используют один и тот же принцип - более сложные модели "штрафуют" за увеличение количества предикторов. К ошибке модели добавляется штраф, который тем больше, чем больше предикторов включено в модель. Рассмотрим это на примере скорректированного *R*<sup>2</sup> и информационных критериев.

**Скорректированный *R*<sup>2</sup>** вычисляется по формуле:

$$ R^2\_{adj} = 1 - (1-R^2) \\cdot \\frac{n-1}{n-k-1}$$

Чем больше число предикторов *k*, тем больше дробь, и тем больше произведение этой дроби на долю необъясненной дисперсии (1 − *R*<sup>2</sup>). Таким образом, доля объясненной дисперсии занижается.

**Информационный критерий Акаике (AIC)** вычисляется на основе дисперсии остатков модели (остаточной суммы квадратов), но он также содержит штрафной компонент, зависящий от числа предикторов:

*A**I**C* = *n*ln(*R**S**S*/*n*)+2(*k* + 2)

Здесь штраф включен во второе слагаемое: *k* + 2 - это общее количество оцениваемых по выборке параметров: *k* угловых коэффициентов, свободный член и стандартная ошибка модели. У AIC нет верхнего и нижнего предела. Меньшее значение AIC соответствует лучшей модели.

Если число наблюдений *n* невелико, то при сравнении моделей по AIC получаются слишком сложные модели с большим числом предикторов. Поэтому была разработана модификация - **скорректированный AIC (Corrected AIC, AICc)**, в который дополнительно включен штраф за сложность, который линейно уменьшается при увеличении размера выборки:

$$ AICc = AIC + \\frac{2 (k+2) (k+3)}{n - k - 3} $$

**Байесовский информационный критерий Шварца (BIC)** вычисляется по аналогичному принципу, однако в нем используется другой штраф:

*B**I**C* = *n*ln(*R**S**S*/*n*)+(*k* + 2)⋅ln*n*

В BIC штраф за увеличении сложности выше, поэтому при использовании этого критерия отбора предпочтение отдается моделям с меньшим числом предикторов.

![](mlr-feature-selection_files/figure-markdown_github/Сравнение%20штрафов%20в%20AIC%20и%20BIC-1.png)

Метод полного перебора
----------------------

Для небольших наборов данных можно применить для выбора наилучшей модели (по заданному критерию) метод полного перебора. Однако число моделей, которые необходимо рассмотреть экспоненциально возрастает, поэтому данный подход невозможно масштабировать.

В R есть функция `leaps::regsubsets()`, которая решает задачу выбора наилучшей модели при заданном числе предикторов (*best subsets regression*). Эта функция использует сравнивает модели на основе скорректированного *R*<sup>2</sup>.

``` r
best_models <- leaps::regsubsets(mpg ~ ., # рассматриваем все возможные предикторы
                                 nbest = 2,  # две лучших модели для каждого числа предикторов
                                 nvmax = 11, # максимально 11 переменных в модели, по умолчанию - 8
                                 data = dplyr::select(cars, country:mpg))

# Сводка по моделям
summary(best_models)
```

    ## Subset selection object
    ## Call: regsubsets.formula(mpg ~ ., nbest = 2, nvmax = 11, data = dplyr::select(cars, 
    ##     country:mpg))
    ## 11 Variables  (and intercept)
    ##              Forced in Forced out
    ## countryJapan     FALSE      FALSE
    ## countryUSA       FALSE      FALSE
    ## typeTruck        FALSE      FALSE
    ## price            FALSE      FALSE
    ## engine_s         FALSE      FALSE
    ## horsepow         FALSE      FALSE
    ## wheelbas         FALSE      FALSE
    ## width            FALSE      FALSE
    ## length           FALSE      FALSE
    ## curb_wgt         FALSE      FALSE
    ## fuel_cap         FALSE      FALSE
    ## 2 subsets of each size up to 11
    ## Selection Algorithm: exhaustive
    ##           countryJapan countryUSA typeTruck price engine_s horsepow wheelbas width length curb_wgt
    ## 1  ( 1 )  " "          " "        " "       " "   " "      " "      " "      " "   " "    "*"     
    ## 1  ( 2 )  " "          " "        " "       " "   " "      " "      " "      " "   " "    " "     
    ## 2  ( 1 )  " "          " "        " "       " "   "*"      " "      " "      " "   " "    " "     
    ## 2  ( 2 )  " "          " "        " "       " "   " "      " "      " "      " "   " "    "*"     
    ## 3  ( 1 )  " "          " "        "*"       " "   " "      "*"      " "      " "   " "    "*"     
    ## 3  ( 2 )  " "          " "        "*"       " "   " "      "*"      " "      " "   " "    " "     
    ## 4  ( 1 )  " "          " "        "*"       " "   " "      "*"      " "      " "   " "    "*"     
    ## 4  ( 2 )  " "          "*"        "*"       " "   "*"      " "      " "      " "   " "    " "     
    ## 5  ( 1 )  " "          " "        "*"       " "   "*"      "*"      " "      " "   " "    "*"     
    ## 5  ( 2 )  " "          "*"        "*"       " "   "*"      " "      " "      " "   " "    "*"     
    ## 6  ( 1 )  " "          "*"        "*"       " "   "*"      "*"      " "      " "   " "    "*"     
    ## 6  ( 2 )  "*"          "*"        "*"       " "   "*"      " "      " "      " "   " "    "*"     
    ## 7  ( 1 )  "*"          "*"        "*"       " "   "*"      "*"      " "      " "   " "    "*"     
    ## 7  ( 2 )  "*"          "*"        "*"       " "   "*"      " "      " "      "*"   " "    "*"     
    ## 8  ( 1 )  "*"          "*"        "*"       "*"   "*"      "*"      " "      " "   " "    "*"     
    ## 8  ( 2 )  "*"          "*"        "*"       " "   "*"      "*"      " "      "*"   " "    "*"     
    ## 9  ( 1 )  "*"          "*"        "*"       "*"   "*"      "*"      "*"      " "   " "    "*"     
    ## 9  ( 2 )  "*"          "*"        "*"       "*"   "*"      "*"      " "      "*"   " "    "*"     
    ## 10  ( 1 ) "*"          "*"        "*"       "*"   "*"      "*"      "*"      "*"   " "    "*"     
    ## 10  ( 2 ) "*"          "*"        "*"       "*"   "*"      "*"      "*"      " "   "*"    "*"     
    ## 11  ( 1 ) "*"          "*"        "*"       "*"   "*"      "*"      "*"      "*"   "*"    "*"     
    ##           fuel_cap
    ## 1  ( 1 )  " "     
    ## 1  ( 2 )  "*"     
    ## 2  ( 1 )  "*"     
    ## 2  ( 2 )  "*"     
    ## 3  ( 1 )  " "     
    ## 3  ( 2 )  "*"     
    ## 4  ( 1 )  "*"     
    ## 4  ( 2 )  "*"     
    ## 5  ( 1 )  "*"     
    ## 5  ( 2 )  "*"     
    ## 6  ( 1 )  "*"     
    ## 6  ( 2 )  "*"     
    ## 7  ( 1 )  "*"     
    ## 7  ( 2 )  "*"     
    ## 8  ( 1 )  "*"     
    ## 8  ( 2 )  "*"     
    ## 9  ( 1 )  "*"     
    ## 9  ( 2 )  "*"     
    ## 10  ( 1 ) "*"     
    ## 10  ( 2 ) "*"     
    ## 11  ( 1 ) "*"

Можно визуализировать результаты сравнения моделей средствами базовой графики R.

``` r
# Создаем палитру менее депрессивных цветов
# См. RColorBrewer::display.brewer.all()
mycolors <- rev(RColorBrewer::brewer.pal(n = 5, name = 'Greens')) 

# Визуализация моделей
plot(best_models, scale = "adjr2", col = mycolors,
     main = "Сравнение лучших моделей по скорректированному R^2")
```

![](mlr-feature-selection_files/figure-markdown_github/Визуализация%20результатов%20сравнения%20моделей-1.png)

На этом графике модели упорядочены по убыванию скорректированного *R*<sup>2</sup>. Каждой модели соответствует одна строка в матрице. Ячейки, закрашенные цветом - это выбранные предикторы, белые ячейки - не включенные в модель переменные.

Вверху находится наилучшая по этому критерию модель, в которую включены все предикторы, кроме длины и ширины машины.

Если выбрать другой критерий ранжирования, то лучшей окажется другая модель. Например, при выборе BIC, в котором используется больший штраф за усложнение модели, результат получится другой:

``` r
# Визуализация моделей
plot(best_models, scale = "bic", col = mycolors, 
     main = "Сравнение лучших моделей по BIC")
```

![](mlr-feature-selection_files/figure-markdown_github/Лучшая%20модель%20по%20BIC-1.png)

Здесь в лучшей модели (с наименьшим BIC) оказалось гораздо меньше переменных - 5 вместо 8.

\*\* Ограничения метода \*\* Помимо неоднозначности результатов в зависимости от выбора критерия оценки моделей, и больших вычислительных затрат, у метода полного перебора есть еще один недостаток: если зависимость между переменными нелинейная и нужно преобразование данных, то такое преобразование автоматически выполняться не будет. Ответственность за выяснение этой необходимости и подготовка данных лежит на аналитике. Также не рассматриваются взаимодействия предикторов.

Пошаговая регрессия
-------------------

**Пошаговая регрессия** (*stepwise regression*) - это эвристический алгоритм для отбора переменных в регрессионную модель, который можно применять даже когда количество возможных предикторов велико и полный перебор невозможен. Алгоритм работает итеративно. На каждом шаге принимается решение, какую переменную лучше всего включить в модель, или исключить из нее, чтобы повысить точность. Существуют три модификации алгоритма пошаговой регрессии:

-   Пошаговое исключение переменных (*backward stepwise*) - путь упрощения сложной модели
-   Пошаговое включение переменных (*forward stepwise*) - путь усложнения простой модели
-   Пошаговый перебор (*Stepwise stepwise*) - путь последовательного изменения модели, при этом на каждом шаге она может быть усложнена или упрощена

Метод пошагового исключения начинает с полной модели и последовательно исключает наихудший предиктор на каждом шаге, до тех пор пока не окажется, что дальнейшее упрощение модели ухудшает ее качество.

Метод пошагового включения действует в обратном напралении: работа начинается с нулевой модели без предикторов, и на каждом шаге определяется, какую из переменных лучше всего включить в модель как предиктор.

Метод пошагового отбора после включения на очередном шаге новой переменной в модель, может исключать из модели добавленные ранее переменные, если это улучшит точность. Такая необходимость возникает в том случае, если переменные коррелированы и добавленная на более позднем шаге переменная содержит ту же информацию, что и ранее добавленная.

Для оценки качества модели на каждом шаге используется какой-либо "штрафной" критерий - например, AIC или скорректированный *R*<sup>2</sup>.

В R алгоритм пошаговой регрессии реализован функцией `MASS:stepAIC()`.

Рассмотрим использование алгоритма пошаговой регрессии на примерах.

Метод пошагового исключения основан на упрощении первоначальной модели. Чтобы задать эту модель, можно использовать формулу, или ранее полученную с помощью `lm()` модель.

``` r
m_backward <- stepAIC(m_full, direction = "backward")
```

    ## Start:  AIC=226
    ## mpg ~ country + type + price + engine_s + horsepow + wheelbas + 
    ##     width + length + curb_wgt + fuel_cap
    ## 
    ##            Df Sum of Sq RSS AIC
    ## - length    1       1.9 574 224
    ## - width     1       2.5 575 224
    ## <none>                  572 226
    ## - wheelbas  1       8.0 580 226
    ## - price     1      11.6 584 226
    ## - curb_wgt  1      15.8 588 228
    ## - horsepow  1      19.8 592 229
    ## - fuel_cap  1      21.6 594 229
    ## - engine_s  1      24.8 597 230
    ## - country   2      35.6 608 231
    ## - type      1      89.7 662 246
    ## 
    ## Step:  AIC=224
    ## mpg ~ country + type + price + engine_s + horsepow + wheelbas + 
    ##     width + curb_wgt + fuel_cap
    ## 
    ##            Df Sum of Sq RSS AIC
    ## - width     1       2.6 577 223
    ## - wheelbas  1       6.8 581 224
    ## <none>                  574 224
    ## - price     1      13.7 588 226
    ## - horsepow  1      21.8 596 228
    ## - curb_wgt  1      21.9 596 228
    ## - fuel_cap  1      23.1 597 228
    ## - engine_s  1      24.1 598 228
    ## - country   2      34.0 608 229
    ## - type      1     108.3 682 248
    ## 
    ## Step:  AIC=223
    ## mpg ~ country + type + price + engine_s + horsepow + wheelbas + 
    ##     curb_wgt + fuel_cap
    ## 
    ##            Df Sum of Sq RSS AIC
    ## - wheelbas  1       5.1 582 222
    ## <none>                  577 223
    ## - price     1      15.4 592 225
    ## - country   2      31.6 608 227
    ## - horsepow  1      24.4 601 227
    ## - engine_s  1      24.8 602 227
    ## - fuel_cap  1      25.9 603 227
    ## - curb_wgt  1      28.7 605 228
    ## - type      1     106.5 683 246
    ## 
    ## Step:  AIC=222
    ## mpg ~ country + type + price + engine_s + horsepow + curb_wgt + 
    ##     fuel_cap
    ## 
    ##            Df Sum of Sq RSS AIC
    ## <none>                  582 222
    ## - price     1      12.2 594 223
    ## - fuel_cap  1      21.4 603 226
    ## - horsepow  1      22.1 604 226
    ## - curb_wgt  1      23.8 606 226
    ## - engine_s  1      28.2 610 227
    ## - country   2      37.3 619 228
    ## - type      1     114.4 696 247

При необходимости, можно отключить вывод результатов на каждом шаге, задав параметр `trace = F`. Можно менять весовой коэффициент для штрафа (параметр `n`). По умолчанию он равен 2 (AIC), если задать величину log(N), где `N` - число наблюдений в выборке, то получится BIC.

Для использования пошагового включения или перебора необходимо задать направление поиска, указав наиболее простую и наиболее полную модели, которые надо рассмотреть, в параметре `scope =`. Здесь мы используем в качестве границ нулевую и полную модели.

Пошаговое включение

``` r
# Нулевая модель
m_null <- lm(mpg ~ 1, data = dplyr::select(cars, country:mpg))

# Прямое включение
m_forward <- stepAIC(m_null, 
                     scope = list(lower = m_null, upper = m_full),
                     direction = 'forward')
```

    ## Start:  AIC=445
    ## mpg ~ 1
    ## 
    ##            Df Sum of Sq  RSS AIC
    ## + curb_wgt  1      1880  918 277
    ## + fuel_cap  1      1799  999 290
    ## + engine_s  1      1521 1277 328
    ## + horsepow  1      1062 1736 374
    ## + width     1      1015 1783 378
    ## + type      1       931 1867 385
    ## + wheelbas  1       692 2106 404
    ## + price     1       676 2122 405
    ## + length    1       561 2238 413
    ## <none>                  2798 445
    ## + country   2         2 2797 449
    ## 
    ## Step:  AIC=277
    ## mpg ~ curb_wgt
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + fuel_cap  1      95.9 822 263
    ## + engine_s  1      85.7 832 264
    ## + type      1      81.7 836 265
    ## + horsepow  1      59.7 858 269
    ## + length    1      21.6 896 276
    ## + price     1      13.7 904 277
    ## <none>                  918 277
    ## + wheelbas  1       6.5 912 278
    ## + width     1       0.5 917 279
    ## + country   2       5.4 913 280
    ## 
    ## Step:  AIC=263
    ## mpg ~ curb_wgt + fuel_cap
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + engine_s  1      80.9 741 249
    ## + horsepow  1      68.8 753 251
    ## + type      1      37.1 785 258
    ## + length    1      28.4 794 259
    ## + wheelbas  1      26.1 796 260
    ## + price     1      19.8 802 261
    ## <none>                  822 263
    ## + width     1       0.1 822 265
    ## + country   2       4.7 817 266
    ## 
    ## Step:  AIC=249
    ## mpg ~ curb_wgt + fuel_cap + engine_s
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + type      1      77.0 664 234
    ## + length    1      42.1 699 242
    ## + wheelbas  1      21.3 720 246
    ## + country   2      29.2 712 247
    ## + width     1      11.2 730 248
    ## <none>                  741 249
    ## + horsepow  1       6.6 735 250
    ## + price     1       0.8 740 251
    ## 
    ## Step:  AIC=234
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + country   2      59.6 605 224
    ## + horsepow  1      45.0 619 226
    ## + price     1      20.9 643 231
    ## + wheelbas  1      20.1 644 232
    ## + length    1      16.6 648 232
    ## <none>                  664 234
    ## + width     1       2.9 661 236
    ## 
    ## Step:  AIC=224
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type + country
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + horsepow  1     10.65 594 223
    ## <none>                  605 224
    ## + width     1      3.19 602 225
    ## + wheelbas  1      2.16 603 225
    ## + price     1      0.76 604 226
    ## + length    1      0.14 605 226
    ## 
    ## Step:  AIC=223
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type + country + horsepow
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + price     1     12.19 582 222
    ## <none>                  594 223
    ## + width     1      2.42 592 225
    ## + wheelbas  1      1.95 592 225
    ## + length    1      0.13 594 225
    ## 
    ## Step:  AIC=222
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type + country + horsepow + 
    ##     price
    ## 
    ##            Df Sum of Sq RSS AIC
    ## <none>                  582 222
    ## + wheelbas  1      5.14 577 223
    ## + width     1      0.87 581 224
    ## + length    1      0.45 581 224

Пошаговый перебор

``` r
m_stepwise <- stepAIC(m_null, 
                      scope = list(lower = m_null, upper = m_full), 
                      direction = 'both')
```

    ## Start:  AIC=445
    ## mpg ~ 1
    ## 
    ##            Df Sum of Sq  RSS AIC
    ## + curb_wgt  1      1880  918 277
    ## + fuel_cap  1      1799  999 290
    ## + engine_s  1      1521 1277 328
    ## + horsepow  1      1062 1736 374
    ## + width     1      1015 1783 378
    ## + type      1       931 1867 385
    ## + wheelbas  1       692 2106 404
    ## + price     1       676 2122 405
    ## + length    1       561 2238 413
    ## <none>                  2798 445
    ## + country   2         2 2797 449
    ## 
    ## Step:  AIC=277
    ## mpg ~ curb_wgt
    ## 
    ##            Df Sum of Sq  RSS AIC
    ## + fuel_cap  1        96  822 263
    ## + engine_s  1        86  832 264
    ## + type      1        82  836 265
    ## + horsepow  1        60  858 269
    ## + length    1        22  896 276
    ## + price     1        14  904 277
    ## <none>                   918 277
    ## + wheelbas  1         6  912 278
    ## + width     1         1  917 279
    ## + country   2         5  913 280
    ## - curb_wgt  1      1880 2798 445
    ## 
    ## Step:  AIC=263
    ## mpg ~ curb_wgt + fuel_cap
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + engine_s  1      80.9 741 249
    ## + horsepow  1      68.8 753 251
    ## + type      1      37.1 785 258
    ## + length    1      28.4 794 259
    ## + wheelbas  1      26.1 796 260
    ## + price     1      19.8 802 261
    ## <none>                  822 263
    ## + width     1       0.1 822 265
    ## + country   2       4.7 817 266
    ## - fuel_cap  1      95.9 918 277
    ## - curb_wgt  1     176.8 999 290
    ## 
    ## Step:  AIC=249
    ## mpg ~ curb_wgt + fuel_cap + engine_s
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + type      1      77.0 664 234
    ## + length    1      42.1 699 242
    ## + wheelbas  1      21.3 720 246
    ## + country   2      29.2 712 247
    ## + width     1      11.2 730 248
    ## <none>                  741 249
    ## + horsepow  1       6.6 735 250
    ## + price     1       0.8 740 251
    ## - curb_wgt  1      51.1 792 257
    ## - engine_s  1      80.9 822 263
    ## - fuel_cap  1      91.1 832 264
    ## 
    ## Step:  AIC=234
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + country   2      59.6 605 224
    ## + horsepow  1      45.0 619 226
    ## + price     1      20.9 643 231
    ## + wheelbas  1      20.1 644 232
    ## + length    1      16.6 648 232
    ## <none>                  664 234
    ## + width     1       2.9 661 236
    ## - curb_wgt  1      33.0 697 240
    ## - fuel_cap  1      33.8 698 240
    ## - type      1      77.0 741 249
    ## - engine_s  1     120.8 785 258
    ## 
    ## Step:  AIC=224
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type + country
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + horsepow  1      10.7 594 223
    ## <none>                  605 224
    ## + width     1       3.2 602 225
    ## + wheelbas  1       2.2 603 225
    ## + price     1       0.8 604 226
    ## + length    1       0.1 605 226
    ## - curb_wgt  1      20.0 625 227
    ## - fuel_cap  1      22.7 627 228
    ## - country   2      59.6 664 234
    ## - type      1     107.3 712 247
    ## - engine_s  1     168.9 774 259
    ## 
    ## Step:  AIC=223
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type + country + horsepow
    ## 
    ##            Df Sum of Sq RSS AIC
    ## + price     1      12.2 582 222
    ## <none>                  594 223
    ## - horsepow  1      10.7 605 224
    ## + width     1       2.4 592 225
    ## + wheelbas  1       1.9 592 225
    ## + length    1       0.1 594 225
    ## - country   2      25.2 619 226
    ## - curb_wgt  1      19.2 613 226
    ## - fuel_cap  1      23.2 617 227
    ## - engine_s  1      28.2 622 228
    ## - type      1     118.0 712 249
    ## 
    ## Step:  AIC=222
    ## mpg ~ curb_wgt + fuel_cap + engine_s + type + country + horsepow + 
    ##     price
    ## 
    ##            Df Sum of Sq RSS AIC
    ## <none>                  582 222
    ## + wheelbas  1       5.1 577 223
    ## - price     1      12.2 594 223
    ## + width     1       0.9 581 224
    ## + length    1       0.5 581 224
    ## - fuel_cap  1      21.4 603 226
    ## - horsepow  1      22.1 604 226
    ## - curb_wgt  1      23.8 606 226
    ## - engine_s  1      28.2 610 227
    ## - country   2      37.3 619 228
    ## - type      1     114.4 696 247

Сравним модели, полученные пошаговым отбором, и лучшую модель, полученную полным перебором вариантов.

``` r
m_best <- lm(mpg ~ type + horsepow + curb_wgt + fuel_cap, data = cars)

memisc::mtable(m_backward, m_forward, m_stepwise, m_best)
```

    ## 
    ## Calls:
    ## m_backward: lm(formula = mpg ~ country + type + price + engine_s + horsepow + 
    ##     curb_wgt + fuel_cap, data = dplyr::select(cars, country:mpg))
    ## m_forward: lm(formula = mpg ~ curb_wgt + fuel_cap + engine_s + type + country + 
    ##     horsepow + price, data = dplyr::select(cars, country:mpg))
    ## m_stepwise: lm(formula = mpg ~ curb_wgt + fuel_cap + engine_s + type + country + 
    ##     horsepow + price, data = dplyr::select(cars, country:mpg))
    ## m_best: lm(formula = mpg ~ type + horsepow + curb_wgt + fuel_cap, data = cars)
    ## 
    ## ========================================================================
    ##                           m_backward  m_forward  m_stepwise   m_best    
    ## ------------------------------------------------------------------------
    ##   (Intercept)             37.921***   37.921***  37.921***   39.738***  
    ##                           (1.286)     (1.286)    (1.286)     (1.044)    
    ##   country: Japan/Europe    1.261*      1.261*     1.261*                
    ##                           (0.572)     (0.572)    (0.572)                
    ##   country: USA/Europe      1.903**     1.903**    1.903**               
    ##                           (0.629)     (0.629)    (0.629)                
    ##   type: Truck/Automobile  -2.917***   -2.917***  -2.917***   -2.899***  
    ##                           (0.550)     (0.550)    (0.550)     (0.536)    
    ##   price                    0.047       0.047      0.047                 
    ##                           (0.027)     (0.027)    (0.027)                
    ##   engine_s                -1.163**    -1.163**   -1.163**               
    ##                           (0.442)     (0.442)    (0.442)                
    ##   horsepow                -0.020*     -0.020*    -0.020*     -0.026***  
    ##                           (0.008)     (0.008)    (0.008)     (0.004)    
    ##   curb_wgt                -1.482*     -1.482*    -1.482*     -1.753**   
    ##                           (0.612)     (0.612)    (0.612)     (0.589)    
    ##   fuel_cap                -0.207*     -0.207*    -0.207*     -0.250**   
    ##                           (0.090)     (0.090)    (0.090)     (0.091)    
    ## ------------------------------------------------------------------------
    ##   R-squared                   0.8         0.8        0.8         0.8    
    ##   adj. R-squared              0.8         0.8        0.8         0.8    
    ##   sigma                       2.0         2.0        2.0         2.1    
    ##   F                          68.1        68.1       68.1       126.9    
    ##   p                           0.0         0.0        0.0         0.0    
    ##   Log-likelihood           -317.7      -317.7     -317.7      -323.5    
    ##   Deviance                  581.8       581.8      581.8       628.4    
    ##   AIC                       655.4       655.4      655.4       659.1    
    ##   BIC                       685.6       685.6      685.6       677.2    
    ##   N                         152         152        152         152      
    ## ========================================================================

\*\* Ограничения метода \*\*

В данном случае, все три алгоритма последовательного перебора привели к одинаковому результату. Он, тем не менее, отличается от лучшей модели, полученной полным перебором. У этой модели меньше предикторов, и значение BIC лучше, чем у моделей, полученных последовательным перебором. Возможно, разница результатов объясняется тем, для отбора моделей использовались разные критерии (AIC и BIC), но возможна и другая причина. Алгоритмы пошагового отбора - "жадные", они принимают локально оптимальное решение на каждом шаге и не могут вернуться назад, если поиск зайдет в тупик. Поэтому гарантий нахождения глобального оптимума - наилучшей возможной модели - нет.

Кроме того, как и в методе полного перебора, ответственность за нелинейные преобразования данных или учет взаимодействия предикторов лежит на аналитике. Методы их автоматически не рассматривают.
