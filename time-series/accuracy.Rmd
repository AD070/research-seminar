---
title: "Оценка ошибки прогноза"
author: "Заходякин Г.В., postlogist@gmail.com"
output: 
  html_document: 
    number_sections: no
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'svg', warning = FALSE) 
# выбор векторного формата для графиков и отключение жалоб на русские шрифты на графиках
options(digits = 4) # Количество значащих цифр при выводе
```


# Введение

В этом блокноте рассмотрены простые ("наивные") методы прогнозирования, используемые для сравнительного анализа эффективности более сложных методов прогнозировния. Также рассмотрены показатели, применяемые для оценки ошибки прогноза.

Материал составлен на основе раздела [2.3](https://www.otexts.org/fpp/2/3) и [2.5](https://www.otexts.org/fpp/2/5) книги: *Hyndman R, Athanasopoulos G. Forecasting Principles and Practice*.

```{r Подключение библиотек}
suppressMessages(library(tidyverse)) # ggplot2 и трансформация данных
suppressMessages(library(forecast)) # анализ временных рядов и прогнозирование
suppressMessages(library(ggfortify)) # Визуализация временных рядов с помощью ggplot2
suppressMessages(library(scales)) # Форматирование осей на графиках ggplot2
suppressMessages(library(fpp)) # Примеры временных рядов
suppressMessages(library(sophisthse)) # Загрузка временных рядов из базы Sophist

suppressMessages(library(stringr))  # Работа с текстовыми строками
suppressMessages(library(lubridate)) # обработка дат
suppressMessages(library(ggseas)) # Расширения ggplot для временных рядов
```

# Простые методы прогнозирования

## Описание

Вначале рассмотрим несколько простых методов прогнозирования. Эти методы иногда оказываются более эффективными, чем сложные. Эти методы прогнозирования используются как основа для сравнения при бенчмаркинге различных методов прогнозирования.

**Метод усреднения** (Average Method)

В этом методе в качестве прогноза на будущие периоды берется среднее значение ряда, вычисленное на всем историческом периоде:

$$ \hat{y}_{T+h} = \frac{1}{T} \sum_{t=1}^{T} y_t $$

Метод также может применяться и для неупорядоченных данных.

В R для реализации этого метода используется функция: `forecast::meanf(y, h)`, где `y` - временной ряд, а `h` - горизонт прогнозирования.

**Наивный метод** (Naïve method)

Наивный прогноз - это простое повторение последнего наблюдения в качестве прогноза на будущие периоды. В R метод реализован двумя функциями: `forecast::naive(y, h)` и `forecast::rwf(y, h)`.

**Сезонный наивный метод** (Seasonal naïve method)

Этот метод использует тот же принцип, однако повторяется не последнее наблюдение, а последнее наблюдение для одноименного периода. Например, прогноз на октябрь 2017 года, сделанный в 2016 году, будет равен значению за октябрь 2016 года.

В R этот метод реализован функцией `forecast::snaive(y, h)`

**Метод дрейфа** (Drift Method)

Дрейф - это медленное изменение уровня ряда. В методе дрейфа вычисляется средний прирост уровня ряда по всем смежным периодам. Затем это значение используется для прогнозирования будущих значений. 

$$ \hat{y}_{T+h} = y_T + \frac{h}{T-1} \sum_{t=2}^{T} (y_t - y_{t-1})$$

Можно показать, что данное выражение эквивалентно:
$$ \hat{y}_{T+h} = y_T + h  \frac{y_T - y_1}{T-1} $$

Т.е. в методе дрейфа прогнозом является продолжение прямой линии, проведенной через первое и последнее наблюдения.

В R метод дрейфа реализован функцией: `forecast::rwf(y, h, drift=TRUE)`.


## Примеры

```{r Производство пива в Австралии - простые методы}

beer2 <- window(ausbeer,start = 1992, end = c(2005, 4))

beer_m <- meanf(beer2, h = 11)
beer_n <- naive(beer2, h = 11)
beer_sn <- snaive(beer2, h = 11)
beer_d <- rwf(beer2, h = 11, drift = T)

autoplot(cbind('Ряд' = beer2, 
               'Усреднение' = beer_m$mean,
               'Наивный прогноз' = beer_n$mean,
               'Сезонный наивный прогноз' = beer_sn$mean,
               'Метод дрейфа' = beer_d$mean)) + 
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

```


Пакет `forecast` рассчитывает и доверительные интервалы для прогноза.

```{r Доверительный интервал}

# График
autoplot(beer_sn, main = 'Прогноз производства пива в Австралии')

# Таблица
beer_sn

```

Загрузка данных из ЕАЭСД (sophist) - импорт, всего (млрд. долл.)

```{r Данные по импорту}
import_table <- sophisthse('IM_T_M')

# Метаданные
import_info <- sophisthse_metadata(import_table) %>%
  filter(tsname == 'IM_T_M') %>%
  select(fullname, unit)
import <- import_table[, 'IM_T_M']

# Оставляем данные с 2005 года
import <- window(import, start = 2005)

# Визуализация
autoplot(import, ts.colour = 'lightskyblue', main = import_info$fullname, ylab = import_info$unit) +
  scale_x_date(date_minor_breaks = 'years')


```

Прогнозирование объема импорта с помощью рассмотренных методов.

```{r Прогнозирование объема импорта}

import_m <- meanf(import, h = 24)
import_n <- naive(import, h = 24)
import_sn <- snaive(import, h = 24)
import_d <- rwf(import, h = 24, drift = T)

autoplot(cbind('Ряд' = import, 
               'Усреднение' = import_m$mean,
               'Наивный прогноз' = import_n$mean,
               'Сезонный наивный прогноз' = import_sn$mean,
               'Метод дрейфа' = import_d$mean)) + 
  labs(y = import_info$unit, title = import_info$fullname,
       color = 'Ряды')

```

# Оценка точности прогнозирования

## Показатели ошибки прогнозирования

Ошибка прогноза в периоде $t$ - это разность фактических и прогнозных значений:

$$ e_t = y_t -\hat{y}_t $$

Ошибку прогноза можно вычислить для каждого прошедшего периода. Для получения общей картины о точности прогнозирования, применяются **показатели ошибки прогнозирования**, которые вычисляются с помощью агрегирования ошибок за все периоды.

Все показатели ошибки прогнозирования можно разделить на две группы: 

- **абсолютные** - зависят от масштаба пронозируемой величины (**scale-dependent**) и, как правило, измеряются в тех же единицах, что и эта величина;

- **относительные** - представляют собой безразмерные отношения и не зависят от масштаба (**scale-independent**). Показатели этой группы удобно использовать для сравнения точности прогнозирования для разных объектов.


Наиболее популярными абсолютными показателями являются *средняя абсолютная ошибка* (Mean Absolute Error, MAE) и **стандартная ошибка** (Root Mean Squared Error, RMSE):

$$ MAE = mean(|e_t|) $$

$$ RMSE = \sqrt{mean(e_t^2)} $$

Оба показателя позволяют сравнивать точность прогнозирования при работе с одним и тем же рядом. MAE легче вычисляется и интерпретируется, а RMSE применяется для построение доверительных интервалов и расчета страхового запаса.

Кроме того, к абсолютным относится еще один показатель - **средняя ошибка** (Mean Error, ME), который позволяет оценить систематическую ошибку (смещение) прогноза:

$$ ME = mean(e_t) $$

Наиболее популярным относительным показателем является **средняя абсолютная ошибка в процентах** (Mean Absolute Percentage Error, MAPE).  Этот показатель вычисляется путем усреднения **относительных ошибок** прогноза:

$$ p_t = 100 \frac{e_t} {y_t} $$

$$ MAPE = mean(|p_t|) $$


Для оценки систематической ошибки прогноза применяется показатель **средняя ошибка в процентах** (Mean Percentage Error, MPE):

$$ MPE = mean(p_t) $$

Относительные ошибки удобны тем, что с их помощью можно сравнивать точность прогнозирования для разных временных рядов, отличающихся масштабом величин.

Недостатком этих показателей является невозможность их вычисления, если встречаются нулевые значения ряда (например, при прогнозировании спроса на малооборачиваемые или сезонные товары). Величина MAPE получается очень большой, когда фактические значения спроса $y_t < 1$.

MAPE и MPE нельзя применять, когда у показателя нет абсолютного нуля (например, при прогнозировании температуры в шкале Цельсия).

Другим способом нормирования ошибок с целью получения относительных показателей является сопоставление их с абсолютной ошибкой наивного метода (**scaling**). Для несезонных рядов используется деление на среднюю абсолютную ошибку наивного прогноза, для сезонных - используется сезонный наивный прогноз.

**Нормированная ошибка** (scaled error) для несезонного ряда:

$$ q_j = \frac{e_j} {\frac{1}{T - 1} \sum_{t=2}^T |y_t - y_{t-1}|} $$


Нормированная ошибка для сезонного ряда:

$$ q_j = \frac{e_j} {\frac{1}{T - m} \sum_{t=m+1}^T |y_t - y_{t-m}|} $$

Для неупорядочынных (перекрестных) данных нормированная ошибка вычисляется относительно стандартного отклонения прогнозируемой величины:

$$ q_j = \frac{e_j} {\frac{1}{N} \sum_{i=1}^N |y_i - \bar{y}|} $$


Средняя абсолютная нормированная ошибка (Mean Absolute Scaled Error) вычисляется путем усреднения нормированных ошибок для всех периодов:

$$ MASE = mean(|q_j|) $$

Для вычисления показателей ошибки в R используется функция `forecast::accuracy()`.

## Пример - ошибка прогноза объема производства пива

Ряд сезонный, поэтому наилучший результат среди простых методов должен давать сезонный наивный  прогноз.

```{r Визуализация прогнозов}

autoplot(cbind('Ряд' = beer2, 
               'Метод усреднения' = beer_m$fitted)) +
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

autoplot(cbind('Ряд' = beer2, 
               'Наивный прогноз' = beer_n$fitted)) +
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

autoplot(cbind('Ряд' = beer2, 
               'С. наивный прогноз' = beer_sn$fitted)) +
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

autoplot(cbind('Ряд' = beer2, 
               'Метод дрейфа' = beer_d$fitted)) +
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

```


```{r Расчет ошибок прогнозирования - производство пива}

a <- rbind(accuracy(beer_m),
        accuracy(beer_n),
        accuracy(beer_sn),
        accuracy(beer_d))

rownames(a) <- c('Среднее', 'Наивный', 'С. наивный', 'Дрейф')
a

```

Показатель ошибки MASE для сезонного нормированного прогноза равен 1. Усреднение в ~2.5 раза хуже по этому показателю, чем сезонный наивный прогноз.

## Разделение на обучающий и тестовый периоды

При выборе метода прогнозирования аналитика интересует не то, как эта модель объясняла прошлое, а то, как она предсказывает будущее. Поэтому показатели ошибки, вычисленные на историческом периоде могут вводить в заблуждение, т.к. можно построить такую модель, которая предсказывает известное прошлое идеально.

Поэтому распространенным приемом для выбора модели является разделение ряда на два периода - **обучающий** (training set) и **тестовый** (test set). При этом модель строится на обучающем периоде, а показатели ошибки вычисляются на тестовом. Этот способ называется **прогнозирование Ex-Post**.

![Прогнозирование Ex-Post](pics/expost.png)

Обычно в качестве тестового множества выбирается порядка 20% наблюдений, однако это ориентировочная величина, которую можно скорректировать исходя из объема имеющихся данных и горизонта прогнозирования. Рекомендуется делать тестовый период как минимум такой же длины, как и горизонт прогнозирования.

В примере о прогнозировании пива модели строились на подмножестве ряда `ausbeer`. Для проверки доступно еще 11 ежеквартальных наблюдений.

```{r Тестовый период для производства пива}
window(beer2, start = 2005)
window(ausbeer, start = 2005)
beer_test <- window(ausbeer, start = 2006)
```

Прогнозы в тестовом периоде можно сравнить с фактическими данными визуально.

```{r}

autoplot(cbind('Ряд' = window(ausbeer, start = 2004),
               'Усреднение' = beer_m$mean,
               'Наивный прогноз' = beer_n$mean,
               'Сезонный наивный прогноз' = beer_sn$mean,
               'Метод дрейфа' = beer_d$mean)) + 
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

```


Функция `accuracy()` автоматически вычисляет показатели ошибки на тестовом периоде, если предоставить данные тестового периода.

```{r Ошибка тестового периода для метода усреднения}
# Метод усреднения
accuracy(beer_m, beer_test)
```

```{r Ошибка тестового периода для наивного прогноза}
# Наивный прогноз
accuracy(beer_n, beer_test)
```

```{r Ошибка тестового периода для сезонного наивного прогноза}
# Сезонный наивный прогноз
accuracy(beer_sn, beer_test)
```

```{r Ошибка тестового периода для метода дрейфа}
# Метод дрейфа
accuracy(beer_d, beer_test)
```


При использовании тестового периода функция вычисляет еще один показатель - **U-статистику Тейла (Theil's U)**. 

Этот показатель похож на MASE, и в нем используется для нормализации показатель ошибки наивного прогноза. Однако, в отличие от MASE, используются не абсолютные а процентные ошибки.  Поэтому данный показатель страдает от тех же недостатков при малых или нулевых значениях ряда, что и показатели MAPE и MPE.

Суммы квадратов процентных ошибок (Sum of Squared Percent Errors, SSPE) для модели и наивного прогноза вычисляются по формулам:

$$ SSPE(модель) = \sum_{t=2}^N \left(\frac{e_t} {y_{t-1}} \right)^2 $$
      
$$ SSPE(\text{наивный прогноз}) = 
    \sum_{t=1}^N  \left( \frac{y_t - y_{t-1}} {y_{t-1}} \right)^2 $$
      

$$ U= \sqrt{ \frac{SSPE(модель)}{SSPE(\text{наивный прогноз}) }} $$

Интерпретация U-статистики Тейла аналогична интерпретации показателя MASE:

- при $U < 1$ используемый метод работает лучше, чем наивный прогноз;
- при $U >= 1$ не имеет смысла использовать этот метод, т.к. он не лучше, чем наивный прогноз.

# Задание

1. Разделите ряд с объемом импорта на обучающий (до декабря 2015 года) и тестовый (с января 2016 года до конца данных) периоды.

2. Разработайте прогноз на 2016 год (тестовый период), используя 4 простых метода прогнозирования.

3. Сравните и интерпретируйте показатели ошибки различных методов прогнозирования на обучающем и тестовом периодах.


