---
title: "Оценка ошибки прогноза"
author: "Заходякин Г.В., postlogist@gmail.com"
output: 
  html_document: 
    number_sections: no
    toc: yes
    toc_depth: 2
---

```{r Настройка, include=TRUE}
knitr::opts_chunk$set(dev = 'png', warning = FALSE) 
# выбор векторного формата для графиков и отключение жалоб на русские шрифты на графиках
options(digits = 4) # Количество значащих цифр при выводе
```


# Введение

Чтобы оценить, насколько эффективно работают методы прогнозирования на определенных данных, применяются **показатели ошибки прогноза**. В этом блокноте рассмотрены несколько групп таких показателей - абсолютные, относительные, сравнительные, которые с различных сторон характеризуют **ошибку прогноза**, т.е. отклонение прогнозируемых и фактических значений. 

Наиболее часто для оценки эффективности прогнозирования используется относительный (процентный) показатель ошибки - MAPE, однако у данного показателя есть ряд недостатков, которые проявляются в случае, когда временной ряд содержит нулевые или очень малые наблюдения. Даже когда нет проблемы нулевых значений, качество прогнозирования сложно оценить лишь с использованием MAPE, поскольку для каждого конкретного объекта прогнозирования действует свой набор факторов (новизна продукта, маркетинговая активность, количество и тип клиентов, степень агрегирования), который определяет пределы точности прогнозирования. Поэтому нельзя ориентироваться на усредненные, "отраслевые" значения ошибки прогнозирования и необходимо сравнивать подходы к прогнозированию в одинаковых условиях. С этой целью будут рассмотрены показатели, основанные на сопоставлении ошибки прогноза применяемого для прогнозирования метода с показателями ошибки простых, "наивных" методов прогнозирования на тех же данных.

Также будут рассмотрены понятия "обучающего" и "тестового" множеств, применяемых при оценке качества предсказаний модели методом Ex-Post.

Материал составлен на основе раздела [2.3](https://www.otexts.org/fpp/2/3) и [2.5](https://www.otexts.org/fpp/2/5) книги: *Hyndman R, Athanasopoulos G. Forecasting Principles and Practice*.

```{r Подключение библиотек}
suppressMessages(library(tidyverse)) # ggplot2 и трансформация данных
suppressMessages(library(forecast)) # анализ временных рядов и прогнозирование
suppressMessages(library(ggfortify)) # Визуализация временных рядов с помощью ggplot2
suppressMessages(library(scales)) # Форматирование осей на графиках ggplot2
suppressMessages(library(fpp)) # Примеры временных рядов
suppressMessages(library(sophisthse)) # Загрузка временных рядов из базы Sophist

suppressMessages(library(stringr))  # Работа с текстовыми строками
suppressMessages(library(lubridate)) # обработка дат
suppressMessages(library(ggseas)) # Расширения ggplot для временных рядов
```

# Простые методы прогнозирования

## Описание

Вначале рассмотрим несколько простых методов прогнозирования. Эти методы иногда оказываются более эффективными, чем сложные. Эти методы прогнозирования используются как основа для сравнения при бенчмаркинге различных методов прогнозирования.

### Метод усреднения (Average Method)

В этом методе в качестве прогноза на будущие периоды берется среднее значение ряда, вычисленное на всем историческом периоде:

$$ \hat{y}_{T+h} = \frac{1}{T} \sum_{t=1}^{T} y_t $$

Метод также может применяться и для неупорядоченных данных (берется среднее по выборке).

В R для реализации этого метода используется функция: `forecast::meanf(y, h)`, где `y` - временной ряд, а `h` - горизонт прогнозирования.

### Наивный метод (Naïve method)

Наивный прогноз - это простое повторение последнего наблюдения в качестве прогноза на будущие периоды. В R метод реализован двумя функциями: `forecast::naive(y, h)` и `forecast::rwf(y, h)`.

### Сезонный наивный метод (Seasonal naïve method)

Этот метод использует тот же принцип, однако повторяется не последнее наблюдение, а последнее наблюдение для одноименного периода. Например, прогноз на октябрь 2017 года, сделанный в 2016 году, будет равен значению за октябрь 2016 года.

В R этот метод реализован функцией `forecast::snaive(y, h)`

### Метод дрейфа (Drift Method)

Дрейф - это медленное изменение уровня ряда. В методе дрейфа вычисляется средний прирост уровня ряда по всем смежным периодам. Затем это значение используется для прогнозирования будущих значений. 

$$ \hat{y}_{T+h} = y_T + \frac{h}{T-1} \sum_{t=2}^{T} (y_t - y_{t-1})$$

Можно показать, что данное выражение эквивалентно:
$$ \hat{y}_{T+h} = y_T + h  \frac{y_T - y_1}{T-1} $$

Т.е. в методе дрейфа прогнозом является продолжение прямой линии, проведенной через первое и последнее наблюдения.

В R метод дрейфа реализован функцией: `forecast::rwf(y, h, drift=TRUE)`.


## Примеры

```{r Производство пива в Австралии - простые методы}

beer2 <- window(ausbeer,start = 1992, end = c(2005, 4))

beer_label <- 'Поквартальный прогноз производства пива в Австралии'
beer_unit <- 'млн. л'

beer_m <- meanf(beer2, h = 11)
beer_n <- naive(beer2, h = 11)
beer_sn <- snaive(beer2, h = 11)
beer_d <- rwf(beer2, h = 11, drift = T)

# Структура объекта
names(beer_m) # см. ?forecast
#View(beer_m)

autoplot(cbind('Ряд' = beer2, 
               'Усреднение' = beer_m$mean,
               'Наивный прогноз' = beer_n$mean,
               'Сезонный наивный прогноз' = beer_sn$mean,
               'Метод дрейфа' = beer_d$mean)) + 
  labs(y = beer_unit, title = beer_label, color = 'Ряды')

```


Пакет `forecast` рассчитывает и доверительные интервалы для прогноза.

```{r Доверительный интервал}

# График
autoplot(beer_sn) + 
  labs(title = beer_label, y = beer_unit)

# Таблица
beer_sn

```

Загрузка данных из ЕАЭСД (sophist) - Ввод в действие жилых домов, млн.кв.метров (CONSTR_Y_NAT)

```{r Данные по строительству}

constr <- sophisthse('CONSTR_Y_NAT') # В таблице один столбец, сразу создался одномерный временной ряд ts

#sophisthse_metadata(constr)

constr_label <- 'Ежегодный ввод в действие жилых домов (CONSTR_Y_NAT)'
constr_unit <- 'млн.кв.м'

# Оставляем данные с 2005 года
constr <- window(constr, start = 2005)

# Визуализация
autoplot(constr, ts.colour = 'lightskyblue') +
  labs(title = constr_label, y = constr_unit)

```

Прогнозирование ввода ноавых жилых домов с помощью рассмотренных методов.

```{r Прогнозирование объема ввода жилых домов}

constr_m <- meanf(constr, h = 10)
constr_n <- naive(constr, h = 10)
constr_d <- rwf(constr, h = 10, drift = T)

autoplot(cbind('Ряд' = constr, 
               'Усреднение' = constr_m$mean,
               'Наивный прогноз' = constr_n$mean,
               'Метод дрейфа' = constr_d$mean)) + 
  labs(y = constr_unit, title = constr_label, color = 'Ряды')


```

# Оценка точности прогнозирования

## Показатели ошибки прогнозирования

Ошибка прогноза в периоде $t$ - это разность фактических и прогнозных значений:

$$ e_t = y_t -\hat{y}_t $$

Ошибку прогноза можно вычислить для каждого прошедшего периода. Для получения общей картины о точности прогнозирования, применяются **показатели ошибки прогнозирования**, которые вычисляются с помощью агрегирования ошибок за все периоды.

Все показатели ошибки прогнозирования можно разделить на две группы: 

- **абсолютные** - зависят от масштаба пронозируемой величины (**scale-dependent**) и, как правило, измеряются в тех же единицах, что и эта величина;

- **относительные** - представляют собой безразмерные отношения и не зависят от масштаба (**scale-independent**). Показатели этой группы удобно использовать для сравнения точности прогнозирования для разных объектов.

Еще одним критерием для классификации показателей может служить их назначение. Одни показатели характеризуют разброс прогнозных и фактических значений, другие - систематическую ошибку, т.е. смещение прогноза.

### Средняя абсолютная ошибка и стандартная ошибка (MAE и RMSE)

Наиболее популярными абсолютными показателями являются *средняя абсолютная ошибка* (Mean Absolute Error, MAE) и **стандартная ошибка** (Root Mean Squared Error, RMSE):

$$ MAE = mean(|e_t|) $$

$$ RMSE = \sqrt{mean(e_t^2)} $$

Оба показателя позволяют сравнивать точность прогнозирования при работе с одним и тем же рядом. MAE легче вычисляется и интерпретируется, а RMSE применяется для построение доверительных интервалов и расчета страхового запаса.

### Средняя ошибка (ME)

Кроме того, к абсолютным относится еще один показатель - **средняя ошибка** (Mean Error, ME), который позволяет оценить систематическую ошибку (смещение) прогноза:

$$ ME = mean(e_t) $$

### Средняя абсолютная ошибка и средняя ошибка в процентах (MAPE и MPE)

Наиболее популярным относительным показателем является **средняя абсолютная ошибка в процентах** (Mean Absolute Percentage Error, MAPE).  Этот показатель вычисляется путем усреднения **относительных ошибок** прогноза:

$$ p_t = 100 \frac{e_t} {y_t} $$

$$ MAPE = mean(|p_t|) $$


Для оценки систематической ошибки прогноза применяется показатель **средняя ошибка в процентах** (Mean Percentage Error, MPE):

$$ MPE = mean(p_t) $$

Относительные ошибки удобны тем, что с их помощью можно сравнивать точность прогнозирования для разных временных рядов, отличающихся масштабом величин.

Недостатком этих показателей является невозможность их вычисления, если встречаются нулевые значения ряда (например, при прогнозировании спроса на малооборачиваемые или сезонные товары). Величина MAPE получается очень большой, когда фактические значения спроса $y_t < 1$.

MAPE и MPE нельзя применять, когда у показателя нет абсолютного нуля (например, при прогнозировании температуры в шкале Цельсия), поскольку для таких данных не имеет смысла само понятие отношения (деления).

Другим способом нормирования ошибок с целью получения относительных показателей является сопоставление их с абсолютной ошибкой наивного метода (**scaling**). Для несезонных рядов используется деление на среднюю абсолютную ошибку наивного прогноза, для сезонных - используется сезонный наивный прогноз.

### Нормированная ошибка (MASE)

**Нормированная ошибка** (scaled error) для несезонного ряда:

$$ q_j = \frac{e_j} {\frac{1}{T - 1} \sum_{t=2}^T |y_t - y_{t-1}|} $$


Нормированная ошибка для сезонного ряда:

$$ q_j = \frac{e_j} {\frac{1}{T - m} \sum_{t=m+1}^T |y_t - y_{t-m}|} $$

Для неупорядочынных (перекрестных) данных нормированная ошибка вычисляется относительно стандартного отклонения прогнозируемой величины:

$$ q_j = \frac{e_j} {\frac{1}{N} \sum_{i=1}^N |y_i - \bar{y}|} $$


Средняя абсолютная нормированная ошибка (Mean Absolute Scaled Error) вычисляется путем усреднения нормированных ошибок для всех периодов:

$$ MASE = mean(|q_j|) $$

Для вычисления показателей ошибки в R используется функция `forecast::accuracy()`.

## Пример - ошибка прогноза объема производства пива

Ряд сезонный, поэтому наилучший результат среди простых методов должен давать сезонный наивный  прогноз.

```{r Визуализация прогнозов}

autoplot(cbind('Ряд' = beer2, 
               'Метод усреднения' = beer_m$fitted)) +
  labs(y = beer_unit, title = beer_label,
       color = 'Ряды')

autoplot(cbind('Ряд' = beer2, 
               'Наивный прогноз' = beer_n$fitted)) +
  labs(y = beer_unit, title = beer_label,
       color = 'Ряды')

autoplot(cbind('Ряд' = beer2, 
               'С. наивный прогноз' = beer_sn$fitted)) +
  labs(y = beer_unit, title = beer_label,
       color = 'Ряды')

autoplot(cbind('Ряд' = beer2, 
               'Метод дрейфа' = beer_d$fitted)) +
  labs(y = beer_unit, title = beer_label,
       color = 'Ряды')

```


```{r Расчет ошибок прогнозирования - производство пива}

a <- rbind(accuracy(beer_m),
        accuracy(beer_n),
        accuracy(beer_sn),
        accuracy(beer_d))

rownames(a) <- c('Среднее', 'Наивный', 'С. наивный', 'Дрейф')
a
```

Показатель ошибки MASE для сезонного нормированного прогноза равен 1. Усреднение в ~2.5 раза хуже по этому показателю, чем сезонный наивный прогноз.

**Примечание:** по умолчанию выводится слишком большое количество значащих цифр. Для упрощения интерпретации показателей можно ограничить количество значащих цифр, как это сделано в блоке `Настройка` в начале блокнота (функция `options()`). Также можно округлить все значения в таблице с помощью функции `round()`.


## Прогнозирование Ex-Post

При выборе метода прогнозирования аналитика интересует не то, как эта модель объясняла прошлое, а то, как она предсказывает будущее. Поэтому показатели ошибки, вычисленные на историческом периоде могут вводить в заблуждение, т.к. можно построить такую модель, которая предсказывает известное прошлое идеально.

Поэтому распространенным приемом для выбора модели является разделение ряда на два периода - **обучающий** (training set) и **тестовый** (test set). При этом модель строится на обучающем периоде, а показатели ошибки вычисляются на тестовом. Этот способ называется **прогнозирование Ex-Post**.

![Прогнозирование Ex-Post](pics/expost.png)

Обычно в качестве тестового множества выбирается порядка 20% наблюдений, однако это ориентировочная величина, которую можно скорректировать исходя из объема имеющихся данных и горизонта прогнозирования. Рекомендуется делать тестовый период как минимум такой же длины, как и горизонт прогнозирования.

В примере о прогнозировании пива модели строились на подмножестве ряда `ausbeer`. Для проверки доступно еще 11 ежеквартальных наблюдений.

```{r Тестовый период для производства пива}
window(beer2, start = 2005)
window(ausbeer, start = 2005)
beer_test <- window(ausbeer, start = 2006)
```

Прогнозы в тестовом периоде можно сравнить с фактическими данными визуально.

```{r Визуальное сравнение прогнозов и факта в тестовом периоде}

autoplot(cbind('Ряд' = window(ausbeer, start = 2004),
               'Усреднение' = beer_m$mean,
               'Наивный прогноз' = beer_n$mean,
               'Сезонный наивный прогноз' = beer_sn$mean,
               'Метод дрейфа' = beer_d$mean)) + 
  labs(y = NULL, title = 'Прогноз производства пива в Австралии',
       color = 'Ряды')

```


Функция `accuracy()` автоматически вычисляет показатели ошибки на тестовом периоде, если предоставить данные тестового периода.

```{r Ошибка тестового периода для метода усреднения}
# Метод усреднения
accuracy(beer_m, beer_test)
```

```{r Ошибка тестового периода для наивного прогноза}
# Наивный прогноз
accuracy(beer_n, beer_test)
```

```{r Ошибка тестового периода для сезонного наивного прогноза}
# Сезонный наивный прогноз
accuracy(beer_sn, beer_test)
```

```{r Ошибка тестового периода для метода дрейфа}
# Метод дрейфа
accuracy(beer_d, beer_test)
```


При использовании тестового периода функция вычисляет еще один показатель - **U-статистику Тейла (Theil's U)**. 

Этот показатель похож на MASE, и в нем используется для нормализации показатель ошибки наивного прогноза. Однако, в отличие от MASE, используются не абсолютные а процентные ошибки.  Поэтому данный показатель страдает от тех же недостатков при малых или нулевых значениях ряда, что и показатели MAPE и MPE.

Суммы квадратов процентных ошибок (Sum of Squared Percent Errors, SSPE) для модели и наивного прогноза вычисляются по формулам:

$$ SSPE(модель) = \sum_{t=2}^N \left(\frac{e_t} {y_{t-1}} \right)^2 $$
      
$$ SSPE(\text{наивный прогноз}) = 
    \sum_{t=1}^N  \left( \frac{y_t - y_{t-1}} {y_{t-1}} \right)^2 $$
      

$$ U= \sqrt{ \frac{SSPE(модель)}{SSPE(\text{наивный прогноз}) }} $$

Интерпретация U-статистики Тейла аналогична интерпретации показателя MASE:

- при $U < 1$ используемый метод работает лучше, чем наивный прогноз;
- при $U >= 1$ не имеет смысла использовать этот метод, т.к. он не лучше, чем наивный прогноз.

# Задание

1. Загрузите из ЕАЭСД (sophist) показатель "Реальная зарплата (WAG_M)"
Разделите ряд с объемом импорта на тестовый (последние 12 месяцев от имеющихся данных) и обучающий (данные с января 2010 года до начала тестового периода). 

2. Используя данные обучающего периода, постройте 4 простых модели прогнозирования (среднее, наивный и сезонный наивный прогноз, прогноз методом дрейфа). Разработайте прогноз на тестовый период.

3. Сравните и интерпретируйте показатели ошибки использованных методов прогнозирования на обучающем и тестовом периодах. Какой метод оказался наиболее точным и почему?

```{r Решение}

```

